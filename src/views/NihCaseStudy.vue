
<template>
<main id="main-content">
    <div class="case-study article container mt-5">
    <div class="row pt-5 justify-content-center">
        <div class="col-lg-8">
            <RouterLink to="/" class="back-to-projects"><span class="arrow">&larr;</span> Back to Projects</RouterLink>
            <header>
            <h1>From Research to Redesign: How Understanding Participant Motivation Changed a National Program</h1>
            <p class="lead"><a href="https://www.figma.com/proto/7VeEN6rgNMHRftC9JYtF9z/ROResearch-Story?page-id=0%3A1&type=design&node-id=1-5595&viewport=402%2C259%2C0.33&t=UFax9nSD6ya9p28E-1&scaling=scale-down&starting-point-node-id=1%3A5595&mode=design">"Research Highlights Story" Prototype</a></p>
            </header>
            <article>
            <p class="lead">Working on the All of Us research program at the National Institutes of Health, I conducted research into participant trust, value, and satisfaction that called into question the program's biggest assumptions about what motivated its participants. This research led me to design a new type of reward: the "Return of Research Story", that aligned with what participants actually wanted, and improved key engagement metrics.</p>

<h2>The Challenge</h2>

<p>The All of Us research program had been investing much of its budget to reward participants in two primary ways: </p>
<ul>
    <li>genetic return of results</li>
    <li>and monetary incentives</li>
</ul>
<p>The assumption was that these were the key drivers of participation and retention. But as I began studying participant motivation and satisfaction, I quickly realized that trust was a major barrier to participation, while value was a key driver of adoption and retention. Understanding this interaction became particularly important to my work to improve program satisfaction and success outcomes.</p>

<h2>Investigating Trust</h2>

<p>To measure and improve trust, I began with a literature review to identify its key facets. I found that trust in medical research and government institutions was closely tied to four factors:</p>
<ul>
<li>Humanity: Does the program feel personal and considerate? Does it prioritize the safety and privacy of participants?</li>
<li>Transparency: Is the process accurate and honest? Is it clear about how the program operates, or how data is handled?</li>
<li>Capability: Is what the program gives back to participants valuable? Do participants believe in the program's competency? Is participation easy?</li>
<li>Reliability: Does the program deliver on its promises? Does it respond to feedback and carry out improvements?</li>
</ul>

<img src="@/assets/nih-trust-1.png" class="w-100" />

<p>I translated these concepts into leading and lagging indicators of trust, cataloging existing measures and identifying gaps. This allowed me to integrate trust assessment into a broader customer experience (CX) strategy, ensuring that participant trust was continuously monitored and improved over time.</p>
<img src="@/assets/nih-trust-4.png" class="w-100" />

<h2>Defining &amp; Measuring Value</h2>

<p>Understanding value required a more complex approach. I conducted a landscape analysis and multiple rounds of qualitative interviews to explore what participants truly found meaningful. I followed up with quantitative surveys to validate these findings and synthesize actionable insights.</p>

<p>One of my key takeaways was that value is not static, but rather highly contextual and changes over time. What a participant values at the start of the program may differ from what they value later.</p>

<p>To quantify this, I adapted a method similar to the Single Ease Question (often used in usability testing) to create a Single Value Question (SVQ). This approach enabled us to measure perceived value at different points in the participant journey, providing a more nuanced and data-driven way to understand evolving motivations.</p>

<img src="@/assets/nih-value-1.png" class="w-100" />


<h2>Measuring Satisfaction and Motivation</h2>

<p>Building on the trust and value research, I designed a survey to directly assess participant satisfaction and motivation. The survey consisted of three key questions: one Likert scale question regarding satisfaction, another about motivation, and an NPS scale question on likelihood to recommend the program. Additionally, an open-text question was included to gather qualitative data points. I conducted analysis using R, comparing responses across many facets including demographics, activity completion, and whether participants received genetic return of results.</p>

<img src="@/assets/nih-survey-1.png" class="w-100" />

<img src="@/assets/nih-survey-2.png" class="w-100" />

<p>The analysis revealed that satisfaction levels did not significantly differ across participant segments or program duration. However, participants who received genetic results expressed notably higher satisfaction levels. Qualitative analysis of open-text responses highlighted a recurring theme of interest in DNA and genetic results among those with low satisfaction or likelihood to recommend.</p>

<p>But the most important finding challenged a core assumption of the program. While it had previously been assumed that monetary incentives and genetic results were the primary motivators for participation, <strong>the data indicated that the desire to contribute to scientific advancement emerged as the predominant motivation.</strong></p>

<h2>Shifting Program Priorities</h2>

<p>These conclusions were foundational and called into question the biggest bets of the research program. By analyzing trust and value metrics alongside the satisfaction data, I helped shift the program's focus away from some of the assumptions about what participants found valuable, toward what participants actually wanted. My research revealed that some of the program's existing value propositions, mainly the heavy investment in monetary incentive and genetic return of results as primary motivators, weren't resonating the way the program assumed, prompting a realignment of offerings and engagement strategies to better match participant expectations.</p>

<h2>The Solution: Return of Research Story</h2>

<p>The research program had a commitment and unique opportunity to return valuable things to participants.</p>

<p>Since my data showed that contribution to science was the top reason for participants to join the program, rather than the monetary incentive, or genetic results, I identified an opportunity to create something valuable that matched with that top motivation, where other programmatic returns and valuable deliverables had not.</p>

<p>I introduced and designed the concept of the <a href="https://www.figma.com/proto/7VeEN6rgNMHRftC9JYtF9z/ROResearch-Story?page-id=0%3A1&type=design&node-id=1-5595&viewport=402%2C259%2C0.33&t=UFax9nSD6ya9p28E-1&scaling=scale-down&starting-point-node-id=1%3A5595&mode=design">"Return of Research Story,"</a> a personalized narrative illustrating the impact of participants' contributions to scientific research. This "story" not only showcases the research conducted using participants' data but also serves as a catalyst for continued participation by highlighting available activities and ongoing scientific endeavors.</p>

<a href="https://www.figma.com/proto/7VeEN6rgNMHRftC9JYtF9z/ROResearch-Story?page-id=0%3A1&type=design&node-id=1-5595&viewport=402%2C259%2C0.33&t=UFax9nSD6ya9p28E-1&scaling=scale-down&starting-point-node-id=1%3A5595&mode=design"><img src="@/assets/research-story.png" class="w-100" /></a>

<h2>Results and Conclusion</h2>

<p>The implementation of the "Return of Research Story" yielded promising results, not only testing well in moderated sessions, but also fostering increased participant engagement metrics in A/B testing with reassessment activities. </p>

<p>This had an opportunity to save the program an enormous amount of money, by matching motivation with value, and returning what participants <strong>actually wanted</strong>.</p>
    

<p>This research led to the development of new trust and value metrics that became key indicators of program success. By collecting participant data, I was able to show which aspects of the program were ineffective and guide improvements toward elements that actually increased trust and perceived value.</p>

<p>This project highlights why it's key to align what we do based on what our research data tells us. When we put our users first and make the most of the insights our studies give us, we can create engaging and usable experiences that meet our business goals.</p>

            </article>
        </div><!--col-->
    </div><!--row-->

</div><!--contain-->
  </main>
</template>

<style scoped>

    </style>
